# Mind2Web Validation Script Generator Configuration

# Network Configuration
network:
  # Hugging Face Hub mirror for users in China or with network issues
  hf_mirror: "https://hf-mirror.com"
  # Connection timeout in seconds
  timeout: 30

# Dataset Configuration
dataset:
  # Which dataset to use
  # dataset_name: "tasksource/planbench"
  # dataset_name: "squad"  # use smaller Squad dataset for testing
  dataset_name: "osunlp/Mind2Web"
  # dataset_name: "MMInstruction/OSWorld-G"
  
  # Dataset configuration name (optional, auto-detect if not specified)
  config_name: ""  # or "" for auto-detection
  
  # Use streaming to avoid downloading entire dataset
  use_streaming: true
  
  # Preferred data split priority (will try in order)
  split_priority: ['validation', 'train', 'test']  # validation split更小
  
  # Number of samples to load from dataset for analysis
  max_samples_to_load: 10
  
  # Number of validation scripts to generate (max representative tasks)
  max_scripts_to_generate: 10
  
  # Data size limits for LLM processing
  max_sample_chars: 50000  # Maximum characters to send to LLM
  enable_smart_truncation: true  # Enable intelligent data extraction for large samples

# OpenAI API Configuration
openai:
  # API credentials and settings
  api_key: ""
  base_url: "https://api.sttai.cc/v1"
  model: "gpt-4o"
  max_tokens: 8000
  temperature: 0.3

# Self-Debug Configuration
debug:
  # Maximum iterations for system feedback debugging
  max_system_feedback_iterations: 3
  
  # Temperature for debugging iterations
  debug_temperature: 0.1

# Generation Pipeline Configuration
pipeline:
  # Whether to save generated scripts to files
  save_scripts_to_files: true
  
  # Directory to save generated scripts (relative to current working directory)
  output_directory: "./validation_scripts"
  
  # Whether to print detailed progress information
  verbose_logging: true 